# -*- coding: utf-8 -*-
"""Untitled89.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10HB2dbIWXyGiHeI-qEnu8Sdch9j1IamM
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from collections import defaultdict

# Step 1: Load and preprocess data
def preprocess_data(file_path):
    df = pd.read_csv(file_path)
    df = df.sort_values(['cookie', 'time'], ascending=[False, True])
    df['visit_order'] = df.groupby('cookie').cumcount() + 1

    df_paths = df.groupby('cookie')['channel'].aggregate(lambda x: x.unique().tolist()).reset_index()
    df_last = df.drop_duplicates('cookie', keep='last')[['cookie', 'conversion']]
    df_paths = pd.merge(df_paths, df_last, how='left', on='cookie')

    df_paths['path'] = df_paths.apply(
        lambda row: ['Start'] + row['channel'] + ['Conversion' if row['conversion'] == 1 else 'Null'], axis=1
    )

    return df_paths[['cookie', 'path']]

# Step 2: Transition state counts
def transition_states(list_of_paths):
    all_states = set(x for path in list_of_paths for x in path)
    transitions = {f"{a}>{b}": 0 for a in all_states for b in all_states}

    for path in list_of_paths:
        for i in range(len(path) - 1):
            transitions[f"{path[i]}>{path[i+1]}"] += 1

    return transitions

# Step 3: Transition probabilities
def transition_probabilities(transition_counts):
    grouped = defaultdict(dict)
    for trans, count in transition_counts.items():
        from_state, to_state = trans.split('>')
        grouped[from_state][to_state] = count

    trans_probs = defaultdict(dict)
    for from_state, to_dict in grouped.items():
        total = sum(to_dict.values())
        if total > 0:
            for to_state, count in to_dict.items():
                trans_probs[f"{from_state}>{to_state}"] = count / total

    return trans_probs

# Step 4: Build transition matrix
def build_transition_matrix(paths, trans_probs):
    states = sorted(set(x for path in paths for x in path))
    matrix = pd.DataFrame(0.0, index=states, columns=states)

    for state in ['Conversion', 'Null']:
        if state in matrix.index:
            matrix.loc[state, state] = 1.0

    for key, prob in trans_probs.items():
        origin, dest = key.split('>')
        matrix.at[origin, dest] = prob

    return matrix

# Step 5: Calculate removal effects
def removal_effects(matrix, base_rate):
    effects = {}
    channels = [ch for ch in matrix.columns if ch not in ['Start', 'Conversion', 'Null']]

    for ch in channels:
        reduced = matrix.drop(index=ch, columns=ch)
        for row in reduced.index:
            if row not in ['Conversion', 'Null']:
                row_sum = reduced.loc[row].sum()
                reduced.loc[row, 'Null'] += (1.0 - row_sum)

        trans = [s for s in reduced.columns if s not in ['Conversion', 'Null']]
        Q = reduced.loc[trans, trans]
        R = reduced.loc[trans, ['Conversion', 'Null']]

        N = np.linalg.inv(np.eye(len(Q)) - Q)
        B = np.dot(N, R)
        start_idx = trans.index('Start')
        new_rate = B[start_idx][0]

        effects[ch] = 1 - new_rate / base_rate

    return effects

# Step 6: Allocate conversions based on removal effect
def markov_attribution_allocation(removal_effects_dict, total_conversions):
    re_sum = sum(removal_effects_dict.values())
    return {ch: (v / re_sum) * total_conversions for ch, v in removal_effects_dict.items()}

# Step 7: Plot attribution histogram
def plot_attributions(attributions):
    sorted_attr = dict(sorted(attributions.items(), key=lambda x: x[1], reverse=True))
    channels = list(sorted_attr.keys())
    values = list(sorted_attr.values())

    plt.figure(figsize=(10, 6))
    bars = plt.bar(channels, values, color='skyblue')

    for bar in bars:
        y = bar.get_height()
        plt.text(bar.get_x() + bar.get_width()/2, y + 10, f'{y:.2f}', ha='center')

    plt.title("Markov Attribution - Attributed Conversions")
    plt.ylabel("Conversions")
    plt.xticks(rotation=30)
    plt.grid(axis='y', linestyle='--', alpha=0.7)
    plt.tight_layout()
    plt.show()

# Optional: Heatmap for transition matrix
def plot_transition_matrix(matrix):
    plt.figure(figsize=(10, 8))
    sns.heatmap(matrix.round(3), annot=True, cmap='Blues', fmt='.3f', linewidths=0.5, cbar_kws={"label": "Transition Probability"})
    plt.title("Markov Chain Transition Matrix Heatmap")
    plt.xlabel("To State")
    plt.ylabel("From State")
    plt.tight_layout()
    plt.show()

# Entry point (for script usage)
if __name__ == '__main__':
    file_path = 'attribution data.csv'  # Replace with your actual file path
    df_paths = preprocess_data(file_path)
    list_of_paths = df_paths['path'].tolist()

    total_conversions = sum(path.count('Conversion') for path in list_of_paths)
    base_conversion_rate = total_conversions / len(list_of_paths)

    trans_counts = transition_states(list_of_paths)
    trans_probs = transition_probabilities(trans_counts)
    trans_matrix = build_transition_matrix(list_of_paths, trans_probs)

    plot_transition_matrix(trans_matrix)

    re_dict = removal_effects(trans_matrix, base_conversion_rate)
    attributions = markov_attribution_allocation(re_dict, total_conversions)

    plot_attributions(attributions)